{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as tr\n",
    "import numpy as np\n",
    "\n",
    "import itertools\n",
    "\n",
    "from PM_models import *\n",
    "from PM_tasks import *\n",
    "from help_amtask import *\n",
    "\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "%load_ext autoreload\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# goal\n",
    "- investigate CRs suited for organizing retrieval in the switching arbitrary maps task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AnalyticPM():\n",
    "  ''' \n",
    "  s/abags: all possible stimuli and actions\n",
    "  mapbag: maps active within a block\n",
    "  '''\n",
    "  def __init__(self,nmaps_per_block=3):\n",
    "    # initialize EM\n",
    "    self.flushEM()\n",
    "    # bags\n",
    "    self.sbag = [0,1,2]\n",
    "    self.abag = [10,11,12]\n",
    "    self.fix_mapbag(nmaps_per_block)\n",
    "    # embedding matrices\n",
    "    self.context_emat = np.eye(len(mapbag))\n",
    "    self.stim_emat = np.eye(len(sbag))\n",
    "    return None\n",
    "  \n",
    "  def fix_mapbag(self,nmaps_per_block):\n",
    "    ''' mapbag: list of maps '''\n",
    "    asets = [i for i in itertools.permutations(self.abag,nmaps_per_block)]\n",
    "    ssets = [i for i in itertools.combinations(self.sbag,nmaps_per_block)]\n",
    "    self.mapbag = [{s:a for s,a in zip(sset,aset)} for sset,aset in itertools.product(ssets,asets)]\n",
    "    return mapbag\n",
    "  \n",
    "  def encode(self,map_idx):\n",
    "    ''' encode single map '''\n",
    "    assert map_idx <= len(self.mapbag)\n",
    "    map_b = self.mapbag[map_idx]\n",
    "    context_b = self.context_emat[map_idx]\n",
    "    # EM = [c_embed,s_embed : act_int]\n",
    "    for stim_idx,act in map_b.items():\n",
    "      stim_embed = self.stim_emat[stim_idx]\n",
    "      emk = [context_b,stim_embed]\n",
    "      self.EMK.append(emk)\n",
    "      self.EMV.append(act)  \n",
    "    return None\n",
    "  \n",
    "  def flushEM(self):\n",
    "    self.EMK = []\n",
    "    self.EMV = []\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm = AnalyticPM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{0: 10, 1: 11, 2: 12},\n",
       " {0: 10, 1: 12, 2: 11},\n",
       " {0: 11, 1: 10, 2: 12},\n",
       " {0: 11, 1: 12, 2: 10},\n",
       " {0: 12, 1: 10, 2: 11},\n",
       " {0: 12, 1: 11, 2: 10}]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pm.mapbag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10, 12, 11, 10, 12, 11, 11, 10, 12]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pm.encode(2)\n",
    "pm.EMV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 10, 1: 11, 2: 12} [1. 0. 0. 0. 0. 0.]\n",
      "s_t [0. 0. 1.]\n",
      "s_t [0. 1. 0.]\n",
      "s_t [1. 0. 0.]\n",
      "s_t [0. 0. 1.]\n",
      "s_t [0. 0. 1.]\n",
      "{0: 10, 1: 11, 2: 12} [1. 0. 0. 0. 0. 0.]\n",
      "s_t [1. 0. 0.]\n",
      "s_t [0. 1. 0.]\n",
      "s_t [0. 0. 1.]\n",
      "s_t [0. 0. 1.]\n",
      "s_t [0. 0. 1.]\n"
     ]
    }
   ],
   "source": [
    "''' generate data '''\n",
    "block_len = 5\n",
    "nblocks = 2\n",
    "\n",
    "# loop over blocks\n",
    "for blocknum in range(nblocks):\n",
    "  # sample map of block and corresponding context vector\n",
    "  mapidx = np.random.randint(len(mapbag))\n",
    "  map_b = mapbag[mapidx]\n",
    "  context_b = context_emat[mapidx]\n",
    "  print(map_b,context_b)\n",
    "  # stim and action sets\n",
    "  sset_b = list(map_b.keys())\n",
    "  aset_b = list(map_b.values())\n",
    "  ## instruction / encoding phase\n",
    "  \n",
    "  ## test / retrieval phase\n",
    "  for trial in range(block_len):\n",
    "    idx_stim_t = np.random.choice(sset_b)\n",
    "    stim_t = stim_emat[idx_stim_t]\n",
    "    print('s_t',stim_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cannonical representations: \n",
    "- low dimensional\n",
    "- structures mirrors environment structure\n",
    "    - gibsonian? \n",
    "\n",
    "### task\n",
    "- percept stimulus generated by environment object has different dimensions\n",
    "\n",
    "### paradigm:\n",
    "\n",
    "- pomdp vs mdp: \n",
    "    - mdp: environment feature that differentiates buckets persists\n",
    "    - pomdp: environment surface level differentiates \n",
    "\n",
    "### EM system\n",
    "- encoding method\n",
    "    - \n",
    "- retreival function\n",
    "    - retrieved memory = f (stimulus history) \n",
    "        - stimulus history is list\n",
    "    - uses distance between current and encoded states\n",
    "        - iteratively compute distance between current state and items in stimhistL\n",
    "\n",
    "- recency effect strongly suggests smoothly decaying \n",
    "- probabilistic? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# environment\n",
    "\n",
    "- instruction phase: \n",
    "    - #nmaps stimulus, action pairs presented \n",
    "    - model encodes\n",
    "    \n",
    "- how will I encode map?\n",
    "    - \n",
    "    - specified by environment as dict\n",
    "    - model has encode map method\n",
    "        - map_i_representation = encode_map(stimulus_i, action_i)\n",
    "\n",
    "- test phase:\n",
    "    - sequentially process #block_len stimuli (no action) \n",
    "    - model retrieves, responds\n",
    "\n",
    "- percept is vector \n",
    "    - subfields:\n",
    "        - e: external (map @instruction, stimulus @test)\n",
    "            - provided by environment\n",
    "        - i: internal (system state)\n",
    "            - integral of e\n",
    "        - c_e: context_e\n",
    "            - environment auto-correlation \n",
    "                - recency effect\n",
    "        - c_i: context_i      \n",
    "            - change point detection \n",
    "                - shifting property\n",
    "                - \"bucket\"\n",
    "\n",
    "- blocks within experiment can have repeated, overlapping or independent mapsets\n",
    "    - curriculum defines mapset sequence used within an experiment\n",
    "    - mapset is dict {stim:action}\n",
    "    - curriculum is \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gen experiment (nblocks,curriculum)\n",
    "# gen block \n",
    "# gen encoding (nmaps)\n",
    "# gen test (num blocks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model\n",
    "- methods\n",
    "    - map_representation = encode_map(stimulus,action)\n",
    "        - iteratively compute individual encoding for each map in mapset\n",
    "        - or compute a single conjunctive representation of mapset\n",
    "    - retrieved_memory = retrieve(percept(stimulus,context))\n",
    "    \n",
    "- keeps track of internal context\n",
    "    - or should this be handled by environment?\n",
    "- \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = TaskArbitraryMaps(2,switchmaps=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [2],\n",
       "        [2],\n",
       "        [2],\n",
       "        [2]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t,i,x,y = task.gen_ep_data(3,2,return_trial_flag=True)\n",
    "t"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
